{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasinha/Desktop/AiPrivaters/ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "import json\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "\n",
    "import ollama\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(BaseModel):\n",
    "    article_hi: str\n",
    "    language: int\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "except OSError:\n",
    "    print(\"Downloading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/translate/\")\n",
    "async def translate(article: Article):\n",
    "    if int(article.language) != 1:\n",
    "        if article.language == 2:\n",
    "            target_lang = \"eng_Latn\"\n",
    "            source_lang = \"hin_Deva\"\n",
    "        else:\n",
    "            target_lang = \"eng_Latn\"\n",
    "            source_lang = \"kan_Knda\"\n",
    "\n",
    "        article_hi = article.article_hi\n",
    "        translator = pipeline(task=\"translation\", model=model, tokenizer=tokenizer, src_lang=source_lang, tgt_lang=target_lang, max_length=100)\n",
    "        output = translator(article.article_hi)\n",
    "        translated_text = output[0]['translation_text']\n",
    "        \n",
    "        answer = ollama.chat(model=\"mistral\", stream=False, messages=[{'role': 'user', 'content': translated_text}])\n",
    "        llm_output = answer[\"message\"][\"content\"]\n",
    "        \n",
    "        translator = pipeline(task=\"translation\", model=model, tokenizer=tokenizer, src_lang=target_lang, tgt_lang=source_lang, max_length=900)\n",
    "        output = translator(llm_output)\n",
    "        translated_text = output[0]['translation_text']\n",
    "        return {\"bot_answer\": translated_text}\n",
    "    else:\n",
    "        article_hi = article.article_hi\n",
    "        answer = ollama.chat(model=\"mistral\", stream=False, messages=[{'role': 'user', 'content': article_hi}])\n",
    "        llm_output = answer[\"message\"][\"content\"]\n",
    "        return {\"bot_answer\": llm_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /Users/adityasinha/Library/Application Support/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken 2ei4O5VVl4qaEnZgG1YxhuzspVU_4WEAzeD6STWdUvwxx5UHe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [11136]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://1e91-117-236-190-193.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
